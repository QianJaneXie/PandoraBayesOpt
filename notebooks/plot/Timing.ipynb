{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "def load_timing_runs(acq, dim):\n",
    "    runs = api.runs(path=\"ziv-scully-group/PandoraBayesOPT\", filters={\n",
    "        \"sweep\": \"equk6hvr\",\n",
    "        \"config.dim\": dim,\n",
    "        \"config.problem\": \"Ackley\",\n",
    "        \"config.policy\": acq})\n",
    "    \n",
    "    configs_and_metrics = []\n",
    "    for run in tqdm(runs):\n",
    "        metric_keys = [\"cumulative cost\",\"runtime\"]\n",
    "        history = run.scan_history(keys = metric_keys, page_size=1_000_000_000)\n",
    "        metrics = {k: [d[k] for d in history] for k in metric_keys}\n",
    "        summary_metric_keys = [\"global optimum value\"]\n",
    "        summary_history = run.scan_history(keys = summary_metric_keys, page_size=1_000_000_000)\n",
    "        metrics.update({k: [d[k] for d in summary_history] for k in summary_metric_keys})\n",
    "        configs_and_metrics.append((run.config, metrics))\n",
    "\n",
    "    return configs_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_functions = {\n",
    "    'ExpectedImprovement':'ExpectedImprovement',\n",
    "    'ThompsonSampling':'ThompsonSampling', \n",
    "    'KnowledgeGradient':'KnowledgeGradient',\n",
    "    'MultiStepLookaheadEI':'MultiStepLookaheadEI',\n",
    "    'Gittins_Lambda_0001':'Gittins_Lambda0001',\n",
    "    }\n",
    "dimensions = [4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.28s/it]\n",
      "100%|██████████| 16/16 [00:19<00:00,  1.25s/it]\n",
      "100%|██████████| 16/16 [00:21<00:00,  1.32s/it]\n",
      "100%|██████████| 16/16 [00:20<00:00,  1.28s/it]\n",
      "100%|██████████| 16/16 [00:22<00:00,  1.40s/it]\n",
      "100%|██████████| 16/16 [00:22<00:00,  1.38s/it]\n",
      "100%|██████████| 16/16 [00:21<00:00,  1.35s/it]\n",
      "100%|██████████| 16/16 [00:20<00:00,  1.29s/it]\n",
      "100%|██████████| 16/16 [00:19<00:00,  1.21s/it]\n",
      "100%|██████████| 16/16 [00:22<00:00,  1.38s/it]\n",
      "100%|██████████| 16/16 [00:21<00:00,  1.32s/it]\n",
      "100%|██████████| 16/16 [00:25<00:00,  1.61s/it]\n",
      "100%|██████████| 16/16 [00:20<00:00,  1.26s/it]\n",
      "100%|██████████| 16/16 [00:20<00:00,  1.26s/it]\n",
      "100%|██████████| 16/16 [00:20<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "grouped_runs = {(a,d): load_timing_runs(a,d) for a in acquisition_functions.keys() for d in (dimensions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpectedImprovement 4 (40, 16)\n",
      "ExpectedImprovement 8 (80, 16)\n",
      "ExpectedImprovement 16 (160, 16)\n",
      "ThompsonSampling 4 (40, 16)\n",
      "ThompsonSampling 8 (80, 16)\n",
      "ThompsonSampling 16 (160, 16)\n",
      "KnowledgeGradient 4 (40, 16)\n",
      "KnowledgeGradient 8 (80, 16)\n",
      "KnowledgeGradient 16 (160, 16)\n",
      "MultiStepLookaheadEI 4 (40, 16)\n",
      "MultiStepLookaheadEI 8 (80, 16)\n",
      "MultiStepLookaheadEI 16 (160, 16)\n",
      "Gittins_Lambda_0001 4 (40, 16)\n",
      "Gittins_Lambda_0001 8 (80, 16)\n",
      "Gittins_Lambda_0001 16 (160, 16)\n"
     ]
    }
   ],
   "source": [
    "for a in acquisition_functions.keys():\n",
    "    for d in dimensions:\n",
    "        config_and_metrics_per_seed = grouped_runs[a,d]\n",
    "\n",
    "        cumulative_cost_per_seed = np.array([m['cumulative cost'] for (_,m) in config_and_metrics_per_seed if len(m['cumulative cost'])>0]).T \n",
    "        runtime_per_seed = np.array([m['runtime'] for (_,m) in config_and_metrics_per_seed if len(m['runtime'])>0]).T\n",
    "        \n",
    "        print(a, d, runtime_per_seed.shape)\n",
    "\n",
    "        runtime_25 = np.quantile(runtime_per_seed, 0.25, axis=1)\n",
    "        runtime_50 = np.quantile(runtime_per_seed, 0.5, axis=1)\n",
    "        runtime_75 = np.quantile(runtime_per_seed, 0.75, axis=1)\n",
    "\n",
    "        output = np.stack((cumulative_cost_per_seed.mean(axis=1), runtime_25, runtime_50, runtime_75),axis=-1)\n",
    "\n",
    "        np.savetxt(f\"results/quartiles/timing/Timing_d{d}_{acquisition_functions[a]}.csv\", output, header=\"cc, q25, q50, q75\", delimiter=', ', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "def load_timing_runs(acq, dim):\n",
    "    runs = api.runs(path=\"ziv-scully-group/PandoraBayesOPT\", filters={\n",
    "        \"sweep\": \"xii0k0tg\",\n",
    "        \"config.dim\": dim,\n",
    "        \"config.problem\": \"Ackley\",\n",
    "        \"config.policy\": acq})\n",
    "    \n",
    "    configs_and_metrics = []\n",
    "    for run in tqdm(runs):\n",
    "        metric_keys = [\"cumulative cost\",\"runtime\"]\n",
    "        history = run.scan_history(keys = metric_keys, page_size=1_000_000_000)\n",
    "        metrics = {k: [d[k] for d in history] for k in metric_keys}\n",
    "        summary_metric_keys = [\"global optimum value\"]\n",
    "        summary_history = run.scan_history(keys = summary_metric_keys, page_size=1_000_000_000)\n",
    "        metrics.update({k: [d[k] for d in summary_history] for k in summary_metric_keys})\n",
    "        configs_and_metrics.append((run.config, metrics))\n",
    "\n",
    "    return configs_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_functions = ['LogExpectedImprovement']\n",
    "dimensions = [4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n",
      "100%|██████████| 16/16 [00:13<00:00,  1.17it/s]\n",
      "100%|██████████| 16/16 [00:13<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "grouped_runs = {(a,d): load_timing_runs(a,d) for a in acquisition_functions for d in (dimensions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogExpectedImprovement 4 (40, 16)\n",
      "LogExpectedImprovement 8 (80, 16)\n",
      "LogExpectedImprovement 16 (160, 16)\n"
     ]
    }
   ],
   "source": [
    "for a in acquisition_functions:\n",
    "    for d in dimensions:\n",
    "        config_and_metrics_per_seed = grouped_runs[a,d]\n",
    "\n",
    "        cumulative_cost_per_seed = np.array([m['cumulative cost'] for (_,m) in config_and_metrics_per_seed if len(m['cumulative cost'])>0]).T \n",
    "        runtime_per_seed = np.array([m['runtime'] for (_,m) in config_and_metrics_per_seed if len(m['runtime'])>0]).T\n",
    "        \n",
    "        print(a, d, runtime_per_seed.shape)\n",
    "\n",
    "        runtime_25 = np.quantile(runtime_per_seed, 0.25, axis=1)\n",
    "        runtime_50 = np.quantile(runtime_per_seed, 0.5, axis=1)\n",
    "        runtime_75 = np.quantile(runtime_per_seed, 0.75, axis=1)\n",
    "\n",
    "        output = np.stack((cumulative_cost_per_seed.mean(axis=1), runtime_25, runtime_50, runtime_75),axis=-1)\n",
    "\n",
    "        np.savetxt(f\"results/quartiles/timing/Timing_d{d}_{a}.csv\", output, header=\"cc, q25, q50, q75\", delimiter=', ', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogExpectedImprovement 4 (40, 16)\n",
      "LogExpectedImprovement 8 (80, 16)\n",
      "LogExpectedImprovement 16 (160, 16)\n"
     ]
    }
   ],
   "source": [
    "for a in acquisition_functions:\n",
    "    for d in dimensions:\n",
    "        config_and_metrics_per_seed = grouped_runs[a,d]\n",
    "\n",
    "        cumulative_cost_per_seed = np.array([m['cumulative cost'] for (_,m) in config_and_metrics_per_seed if len(m['cumulative cost'])>0]).T \n",
    "        runtime_per_seed = np.array([m['runtime'] for (_,m) in config_and_metrics_per_seed if len(m['runtime'])>0]).T\n",
    "        \n",
    "        print(a, d, runtime_per_seed.shape)\n",
    "\n",
    "        mean = np.mean(runtime_per_seed, axis=1)\n",
    "        se = np.std(runtime_per_seed, axis=1, ddof=1) / np.sqrt(runtime_per_seed.shape[1])\n",
    "        \n",
    "        mean_plus_2se = mean + 2 * se\n",
    "        mean_minus_2se = mean - 2 * se\n",
    "\n",
    "        output = np.stack((cumulative_cost_per_seed.mean(axis=1), mean_minus_2se, mean, mean_plus_2se),axis=-1)\n",
    "\n",
    "        np.savetxt(f\"results/SE/timing/Timing_d{d}_{a}.csv\", output, header=\"cc, mean-2se, mean, mean+2se\", delimiter=', ', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
