{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcc30f5-8177-4caf-9894-76de754c393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n",
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-2.]), std = tensor([nan])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# use a GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set default tensor type to float64\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "seed = 0\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.likelihoods import FixedNoiseGaussianLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "\n",
    "# Example Usage for 1D\n",
    "dim = 16\n",
    "\n",
    "# Define your kernel\n",
    "nu = 2.5\n",
    "lengthscale = 0.1\n",
    "outputscale = 1.0\n",
    "base_kernel = MaternKernel(nu=nu).double()\n",
    "base_kernel.lengthscale = torch.tensor([[lengthscale]])\n",
    "scale_kernel = ScaleKernel(base_kernel).double()\n",
    "scale_kernel.outputscale = torch.tensor([[outputscale]])\n",
    "\n",
    "# Define Noise Level\n",
    "noise_level = 1e-4\n",
    "\n",
    "# Initialize Placeholder Data with Correct Dimensions\n",
    "num_samples = 1  # Replace with actual number of samples\n",
    "num_features = dim  # Replace with actual number of features\n",
    "train_X = torch.empty(num_samples, num_features)  # Placeholder data\n",
    "train_Y = torch.empty(num_samples, 1)             # Placeholder data\n",
    "Yvar = torch.ones(num_samples) * noise_level\n",
    "\n",
    "# Initialize Model\n",
    "model = SingleTaskGP(train_X, train_Y, likelihood = FixedNoiseGaussianLikelihood(noise=Yvar), covar_module=scale_kernel)\n",
    "\n",
    "from botorch.sampling.pathwise import draw_kernel_feature_paths\n",
    "matern_sample = draw_kernel_feature_paths(model, sample_shape=torch.Size([1]))\n",
    "def objective_function(x):\n",
    "    return matern_sample(x).squeeze(0).detach()\n",
    "\n",
    "from botorch.utils.sampling import optimize_posterior_samples\n",
    "# Find the global optimum\n",
    "maximize = True\n",
    "bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "global_optimum_point, global_optimum_value = optimize_posterior_samples(paths=matern_sample, bounds=bounds, raw_samples=1024*dim, num_restarts=20*dim, maximize=maximize)\n",
    "\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "# Set up the kernel\n",
    "base_kernel = MaternKernel(nu=nu).double()\n",
    "base_kernel.lengthscale = lengthscale\n",
    "base_kernel.raw_lengthscale.requires_grad = False\n",
    "scale_kernel = ScaleKernel(base_kernel).double()\n",
    "scale_kernel.outputscale = torch.tensor([[outputscale]])\n",
    "scale_kernel.raw_outputscale.requires_grad = False\n",
    "\n",
    "maximize = True\n",
    "output_standardize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adaa5932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.2982]), std = tensor([0.9299])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.         0.27417155 0.7741499  0.02928046], New value: -1.3433043385822367\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.2872643309805145\n",
      "Cumulative cost: 1.0\n",
      "Running time: 8.120061999999999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3932]), std = tensor([0.9368])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, New point: [0.97264644 0.88428744 0.80060517 0.67955449], New value: 0.09134786346977403\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.116960570132031\n",
      "Cumulative cost: 2.0\n",
      "Running time: 9.721238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from pandora_bayesopt.bayesianoptimizer import BayesianOptimizer\n",
    "from pandora_bayesopt.acquisition.stable_gittins import LogGittinsIndex\n",
    "num_iterations = 2\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Create an instance of BayesianOptimizer\n",
    "LogPBGI_optimizer = BayesianOptimizer( \n",
    "        dim=dim, \n",
    "        maximize=maximize, \n",
    "        initial_points=init_x,\n",
    "        objective=objective_function, \n",
    "        output_standardize=output_standardize\n",
    "    )\n",
    "# Run the optimization\n",
    "LogPBGI_optimizer.run(\n",
    "            num_iterations = num_iterations, \n",
    "            acquisition_function_class = LogGittinsIndex,\n",
    "            lmbda = 0.0001\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5d8a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.2982]), std = tensor([0.9299])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.         0.27417155 0.7741499  0.02928046], New value: -1.3433043385821861\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.287264330980509\n",
      "Cumulative cost: 1.0\n",
      "Running time: 3.7586699999999986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3932]), std = tensor([0.9368])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, New point: [0.97264644 0.88428744 0.80060517 0.67955449], New value: 0.09134786351958663\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.116960570132016\n",
      "Cumulative cost: 2.0\n",
      "Running time: 4.349054000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from pandora_bayesopt.bayesianoptimizer import BayesianOptimizer\n",
    "from pandora_bayesopt.acquisition.gittins import LogVanillaGittinsIndex\n",
    "num_iterations = 2\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Create an instance of BayesianOptimizer\n",
    "LogVanillaPBGI_optimizer = BayesianOptimizer( \n",
    "        dim=dim, \n",
    "        maximize=maximize, \n",
    "        initial_points=init_x,\n",
    "        objective=objective_function, \n",
    "        output_standardize=output_standardize\n",
    "    )\n",
    "# Run the optimization\n",
    "LogVanillaPBGI_optimizer.run(\n",
    "            num_iterations = num_iterations, \n",
    "            acquisition_function_class = LogVanillaGittinsIndex,\n",
    "            lmbda = 0.0001\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8febff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.2982]), std = tensor([0.9299])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.         0.27414241 0.77417126 0.02928116], New value: -1.3432093708360693\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.287264330692003\n",
      "Cumulative cost: 1.0\n",
      "Running time: 10.250326999999999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3932]), std = tensor([0.9368])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, New point: [0.97261306 0.88430817 0.8006507  0.67954832], New value: 0.09211499885115043\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.1169288839850147\n",
      "Cumulative cost: 2.0\n",
      "Running time: 11.521773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from pandora_bayesopt.bayesianoptimizer import BayesianOptimizer\n",
    "from pandora_bayesopt.acquisition.stable_gittins import RobustGittinsIndex\n",
    "num_iterations = 2\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Create an instance of BayesianOptimizer\n",
    "RobustPBGI_optimizer = BayesianOptimizer( \n",
    "        dim=dim, \n",
    "        maximize=maximize, \n",
    "        initial_points=init_x,\n",
    "        objective=objective_function, \n",
    "        output_standardize=output_standardize\n",
    "    )\n",
    "# Run the optimization\n",
    "RobustPBGI_optimizer.run(\n",
    "            num_iterations = num_iterations, \n",
    "            acquisition_function_class = RobustGittinsIndex,\n",
    "            lmbda = 0.0001\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4f3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.0604]), std = tensor([0.9419])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.24381135 0.29459949 0.13814356 0.34680617 0.48369523 0.33734348\n",
      " 0.07876036 0.5354155  0.1558262  0.45535102 0.52425464 0.09485292\n",
      " 0.91282026 0.71975069 0.34654306 0.93534072], New value: -1.177566154869577\n",
      "Best observed value: 1.7826202828511388\n",
      "Current acquisition value: 3.6182402817000687\n",
      "Cumulative cost: 1.0\n",
      "Running time: 34.578129000000004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.0923]), std = tensor([0.9469])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, New point: [0.16334457 0.30589237 0.         0.28729548 0.34783276 0.27995139\n",
      " 0.1941246  0.62273797 0.16048581 0.65909928 0.84886096 0.30901299\n",
      " 0.95239987 0.69477847 0.30311739 0.87845621], New value: 1.8079968250560587\n",
      "Best observed value: 1.8079968250560587\n",
      "Current acquisition value: 3.710353374090138\n",
      "Cumulative cost: 2.0\n",
      "Running time: 44.52635000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from pandora_bayesopt.bayesianoptimizer import BayesianOptimizer\n",
    "from pandora_bayesopt.acquisition.gittins import GittinsIndex\n",
    "num_iterations = 2\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Create an instance of BayesianOptimizer\n",
    "PBGI_optimizer = BayesianOptimizer( \n",
    "        dim=dim, \n",
    "        maximize=maximize, \n",
    "        initial_points=init_x,\n",
    "        objective=objective_function, \n",
    "        output_standardize=output_standardize\n",
    "    )\n",
    "# Run the optimization\n",
    "PBGI_optimizer.run(\n",
    "            num_iterations = num_iterations, \n",
    "            acquisition_function_class = GittinsIndex,\n",
    "            lmbda = 0.0001\n",
    "        )\n",
    "PBGI_best_history = PBGI_optimizer.get_best_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
